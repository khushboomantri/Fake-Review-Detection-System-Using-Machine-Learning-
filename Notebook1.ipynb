{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Spam Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up the folder paths in which the dataset is presetn**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_deceptive_folder_path = './negative_polarity/deceptive_from_MTurk/'\n",
    "neg_true_folder_path = './negative_polarity/truthful_from_Web/'\n",
    "pos_deceptive_folder_path = './positive_polarity/deceptive_from_MTurk/'\n",
    "pos_true_folder_path = './positive_polarity/truthful_from_TripAdvisor/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Initialising the lists in which the polarity, review and either it's fake or true will be stored**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_class = []\n",
    "reviews = []\n",
    "spamity_class =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Since we have 5 folders in each folder in our dataset, I am using a for loop to iterate through each of the folder and collect datas (i.e Polarity, Review, Fake or True) and store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    insideptru = pos_true_folder_path + 'fold' + str(i) \n",
    "    insidepdec = pos_deceptive_folder_path + 'fold' + str(i)\n",
    "    insidentru = neg_true_folder_path + 'fold' + str(i) \n",
    "    insidendec = neg_deceptive_folder_path + 'fold' + str(i) \n",
    "    pos_list = []\n",
    "    for data_file in sorted(os.listdir(insidendec)):\n",
    "        polarity_class.append('negative')\n",
    "        spamity_class.append(str(data_file.split('_')[0]))\n",
    "        with open(os.path.join(insidendec, data_file)) as f:\n",
    "                contents = f.read()\n",
    "                reviews.append(contents)\n",
    "    for data_file in sorted(os.listdir(insidentru)):\n",
    "        polarity_class.append('negative')\n",
    "        spamity_class.append(str(data_file.split('_')[0]))\n",
    "        with open(os.path.join(insidentru, data_file)) as f:\n",
    "                contents = f.read()\n",
    "                reviews.append(contents)\n",
    "    for data_file in sorted(os.listdir(insidepdec)):\n",
    "        polarity_class.append('positive')\n",
    "        spamity_class.append(str(data_file.split('_')[0]))\n",
    "        with open(os.path.join(insidepdec, data_file)) as f:\n",
    "                contents = f.read()\n",
    "                reviews.append(contents)\n",
    "    for data_file in sorted(os.listdir(insideptru)):\n",
    "        polarity_class.append('positive')\n",
    "        spamity_class.append(str(data_file.split('_')[0]))\n",
    "        with open(os.path.join(insideptru, data_file)) as f:\n",
    "                contents = f.read()\n",
    "                reviews.append(contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Making the dataframe using pandas to store polarity, reviews and true or fake **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_fm = pd.DataFrame({'polarity_class':polarity_class,'review':reviews,'spamity_class':spamity_class})\n",
    "\n",
    "data_fm.loc[data_fm['spamity_class']=='d','spamity_class']=\"__label__deceptive\"\n",
    "data_fm.loc[data_fm['spamity_class']=='t','spamity_class']=\"__label__true\"\n",
    "data_fm.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Splitting the dataset to training and testing (0.7 and 0.3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fm = pd.DataFrame({'polarity_class':polarity_class,'review':reviews,'spamity_class':spamity_class})\n",
    "data_fm.loc[data_fm['spamity_class']=='d','spamity_class']=0\n",
    "data_fm.loc[data_fm['spamity_class']=='t','spamity_class']=1\n",
    "data_x = data_fm['review']\n",
    "\n",
    "data_y = np.asarray(data_fm['spamity_class'],dtype=int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Splitting the dataset to training and testing (0.8 and 0.2)**\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2,random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Using CountVectorizer() method to extract features from the text reviews and convert it to numeric data, which can be used to train the classifier **\n",
    "\n",
    "# *Using fit_transform() for X_train and only using transform() for X_test*\n",
    "\n",
    "cv =  CountVectorizer()\n",
    "X_traincv = cv.fit_transform(X_train)\n",
    "X_testcv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traincv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_test = CountVectorizer(vocabulary=cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.vocabulary_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Using Naive Bayes Multinomial method as the classifier and training the data**\n",
    "nbayes = MultinomialNB()\n",
    "nbayes.fit(X_traincv, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Predicting the fake or deceptive reviews**\n",
    "# *using X_testcv : which is vectorized such that the dimensions are matched*\n",
    "y_predictions = nbayes.predict(X_testcv)\n",
    "y_result = list(y_predictions)\n",
    "yp=[\"True\" if a==1 else \"Deceptive\" for a in y_result]\n",
    "X_testlist = list(X_test)\n",
    "output_fm = pd.DataFrame({'Review':X_testlist ,'True(1)/Deceptive(0)':yp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy % :\",metrics.accuracy_score(y_test, y_predictions)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall Score: \",recall_score(y_test, y_predictions, average='micro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_predictions)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (confusion_matrix(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[31]:\n",
    "\n",
    "\n",
    "#Checking the revies from Trip Advisor and Web\n",
    "def test_string(s):\n",
    "    X_testcv = (cv.transform([s]).toarray())\n",
    "    y_predict = nbayes.predict(X_testcv)\n",
    "    return y_predict\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "test_string(\"The hotel was bad.The room had a 27-inch Samsung led tv, a microwave.The room had a double bed\")\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "test_string(\"My family and I are huge fans of this place. The staff is super nice, and the food is great. The chicken is very good, and the garlic sauce is perfect. Ice cream topped with fruit is delicious too. Highly recommended!\")\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "#MTurk\n",
    "test_string(\"Truly, DO NOT stay at this hotel. When we arrived in our room, it was clear that the carpet hadn't been vacuumed\")\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "\n",
    "#Trip Advisor\n",
    "test_string(\"The food is Asian fusion, and truly wonderful -- as a gourmand and life-long foodie, I appreciate great food when I taste it\")\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "#web\n",
    "test_string(\"The elevator system was impossible. It seems they were trying to improve it but only made it worse.\")\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "f = sns.countplot(x='spamity_class', data=data_fm)\n",
    "f.set_title(\"Sentiment distribution\")\n",
    "f.set_xticklabels(['Negative', 'Positive'])\n",
    "plt.xlabel(\"\");\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "text = \" \".join(review for review in data_fm.review)\n",
    "print (\"There are {} words in the combination of all review.\".format(len(text)))\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stopwords.words(\"english\")).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show();\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "class_names = [\"negative\", \"positive\"]\n",
    "fig,ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Blues\", fmt=\"d\",cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual sentiment')\n",
    "plt.xlabel('Predicted sentiment');\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
